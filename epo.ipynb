{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, NonlinearConstraint\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSCI ACWI', 'MWITR', 'TBSP', 'EURPLN', 'EDO', 'Bloomberg Barclays Global Aggre', 'Gold spot price', 'Global aggregate euro hdg', 'EURO STOXX 50 Daily Leverage', 'Bloomberg Barclays Global Corpo']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 456 entries, 1985-01-01 to 2022-12-01\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Mwig40tr             155 non-null    float64\n",
      " 1   TBSP                 191 non-null    float64\n",
      " 2   EDO                  225 non-null    float64\n",
      " 3   ACWI                 254 non-null    float64\n",
      " 4   GovBondG7            254 non-null    float64\n",
      " 5   GlobalCorporate      123 non-null    float64\n",
      " 6   Gold                 254 non-null    float64\n",
      " 7   GABHDG               61 non-null     float64\n",
      " 8   EURO_STOXX_Leverage  252 non-null    float64\n",
      " 9   Fallen_Angels        78 non-null     float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 55.4 KB\n"
     ]
    }
   ],
   "source": [
    "xl = pd.ExcelFile('wartosci_walorow_12_22.xlsx')\n",
    "sheets = xl.sheet_names\n",
    "\n",
    "merged = xl.parse(sheets.pop(0))\n",
    "print(sheets)\n",
    "\n",
    "for sheet in sheets:\n",
    "    data = xl.parse(sheet)    \n",
    "    merged = merged.merge(data, on='Date', how='left') \n",
    "\n",
    "xl.close()\n",
    "\n",
    "assets = merged.columns[1:]\n",
    "price_changes = merged[assets].pct_change()\n",
    "price_changes.set_index(merged['Date'], inplace=True)\n",
    "\n",
    "euro_assets = ['ACWI', 'GovBondG7', 'GlobalCorporate', 'Gold', 'GABHDG', 'EURO_STOXX_Leverage', 'Fallen_Angels']\n",
    "pln_assets = ['Mwig40tr', 'TBSP', 'EDO']\n",
    "\n",
    "pln = merged[euro_assets].apply(lambda x: x * merged['EURPLN'])\n",
    "pln_chng = pln.pct_change()\n",
    "pln_chng.set_index(merged['Date'], inplace=True)\n",
    "pln_chng = pd.merge(price_changes[pln_assets], pln_chng, left_index=True, right_index=True)\n",
    "\n",
    "assets = pln_chng\n",
    "assets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkedCovariance(returns: pd.DataFrame, w: int):\n",
    "    std = np.diag(returns.std()*np.sqrt(12))\n",
    "    corr = returns.corr('pearson')\n",
    "    shrinked_corr = (1-w)*corr + np.ones_like(corr)*w \n",
    "    result = std @ shrinked_corr @ std\n",
    "    return std,corr, shrinked_corr, result\n",
    "\n",
    "def pstd(cov_matrix, weights):\n",
    "    return np.sqrt(weights.T @ cov_matrix @ weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TBSP      ACWI\n",
      "TBSP  0.002233 -0.000662\n",
      "ACWI -0.000662  0.023129\n",
      "[[0.04725282 0.        ]\n",
      " [0.         0.15208061]]\n",
      "          TBSP      ACWI\n",
      "TBSP  1.000000 -0.092152\n",
      "ACWI -0.092152  1.000000\n",
      "          TBSP      ACWI\n",
      "TBSP  1.000000  0.453924\n",
      "ACWI  0.453924  1.000000\n",
      "          0         1\n",
      "0  0.002233  0.003262\n",
      "1  0.003262  0.023129\n",
      "---\n",
      "0.09146392619858458\n",
      "---\n",
      "0.10123873094081719\n"
     ]
    }
   ],
   "source": [
    "assets_names = ['TBSP', 'ACWI']\n",
    "\n",
    "portfolio_returns = assets.iloc[-120:][assets_names]\n",
    "\n",
    "std, corr, sh_corr, res = shrinkedCovariance(portfolio_returns,0.5)\n",
    "cov = portfolio_returns.cov()*12\n",
    "\n",
    "print (portfolio_returns.cov()*12)\n",
    "print(std)\n",
    "print(corr)\n",
    "print(sh_corr)\n",
    "print(res)\n",
    "print('---')\n",
    "print(pstd(cov, np.array([0.4, 0.6])))\n",
    "print('---')\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBSP    0.058287\n",
      "ACWI    0.180158\n",
      "dtype: float64\n",
      "TBSP    0.019728\n",
      "ACWI    0.156034\n",
      "dtype: float64\n",
      "TBSP    0.024732\n",
      "ACWI    0.129339\n",
      "dtype: float64\n",
      "TBSP    0.044049\n",
      "ACWI    0.150289\n",
      "dtype: float64\n",
      "---\n",
      "0.10942527346768507\n",
      "0.09450573239453121\n",
      "0.07687067421906144\n",
      "0.08952406152781506\n",
      "---\n",
      "0.126273078746576\n",
      "0.09980622208789802\n",
      "0.08496410489639229\n",
      "0.10352840991202439\n"
     ]
    }
   ],
   "source": [
    "ret = assets.iloc[-60:][assets_names]\n",
    "ret_24 = assets.iloc[-84:-24][assets_names]\n",
    "ret_48 = assets.iloc[-108:-48][assets_names]\n",
    "ret_150 = assets.iloc[-150:][assets_names]\n",
    "print(ret.std()*np.sqrt(12))\n",
    "print(ret_24.std()*np.sqrt(12))\n",
    "print(ret_48.std()*np.sqrt(12))\n",
    "print(ret_150.std()*np.sqrt(12))\n",
    "print('---')\n",
    "\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0)\n",
    "std, corr, sh_corr, res_24 = shrinkedCovariance(ret_24,0)\n",
    "std, corr, sh_corr, res_48 = shrinkedCovariance(ret_48,0)\n",
    "std, corr, sh_corr, res_150 = shrinkedCovariance(ret_150,0)\n",
    "\n",
    "\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "print(pstd(res_24, np.array([0.4, 0.6])))\n",
    "print(pstd(res_48, np.array([0.4, 0.6])))\n",
    "print(pstd(res_150, np.array([0.4, 0.6])))\n",
    "\n",
    "\n",
    "print('---')\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0.75)\n",
    "std, corr, sh_corr, res_24 = shrinkedCovariance(ret_24,0.75)\n",
    "std, corr, sh_corr, res_48 = shrinkedCovariance(ret_48,0.75)\n",
    "std, corr, sh_corr, res_150 = shrinkedCovariance(ret_150,0.75)\n",
    "\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "print(pstd(res_24, np.array([0.4, 0.6])))\n",
    "print(pstd(res_48, np.array([0.4, 0.6])))\n",
    "print(pstd(res_150, np.array([0.4, 0.6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ef_port_analytically(rets, covm, targ):\n",
    "    \"\"\"Solve for the efficient frontier weights for a given expected return\n",
    "    vector `rets`, covariance matrix `covm`, and expected portfolio return\n",
    "    `targ`.\n",
    "    \"\"\"\n",
    "    N = rets.shape[0]\n",
    "    u = np.array([targ, 1])[:, None]\n",
    "    U = np.vstack([rets, np.ones_like(rets)]).T\n",
    "\n",
    "    covm_inv = np.linalg.solve(covm, np.eye(N))\n",
    "    M        = U.T @ covm_inv @ U\n",
    "    M_inv    = np.linalg.solve(M, np.eye(2))\n",
    "    weights  = covm_inv @ U @ M_inv @ u\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   ]\n",
      " [1.085]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(expectedMean, means: np.array, cov_table: np.array):\n",
    "\n",
    "    constraint1 = NonlinearConstraint(lambda x : x.sum(),1,1)\n",
    "    constraint2 = NonlinearConstraint(lambda x: x.dot(means)*12, expectedMean, expectedMean)\n",
    "    constraint3 = NonlinearConstraint(lambda x: np.all(np.any([x >=0.05, x == 0], axis=0)).astype(int),True,True)\n",
    "    assets_constraints = [(0.0,1),(0.0,1)]\n",
    "    obj = lambda x: x.T@cov_table@x\n",
    "    start = [1/len(means) for n in range(len(means))]\n",
    "    result = minimize(obj,start,constraints=[constraint1, constraint2],bounds=assets_constraints)\n",
    "    #result = np.append(result.x, [expectedMean], [result.fun])    \n",
    "\n",
    "    return np.array(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9503457 0.0496543]\n",
      "[0.95748907 0.04251093]\n"
     ]
    }
   ],
   "source": [
    "print(optimize(0.07,ret.mean()*12,res.cov()*12))\n",
    "print(optimize(0.06,ret.mean()*12,res.cov()*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBSP    0.036798\n",
      "ACWI    0.103870\n",
      "dtype: float64\n",
      "          0         1\n",
      "0  0.003397  0.007743\n",
      "1  0.007743  0.032457\n",
      "0.11329275030994841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65407523],\n",
       "       [0.34592477]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = assets.iloc[-60:][assets_names]\n",
    "ret_150 = assets.iloc[-180:][assets_names]\n",
    "\n",
    "means = ret_150.mean()*12\n",
    "#means = np.array([0.035, 0.085])\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0.75)\n",
    "print(means)\n",
    "print(res)\n",
    "print(pstd(res, np.array([0.5,0.5])))\n",
    "\n",
    "target = 0.06\n",
    "av = 10\n",
    "\n",
    "#1/av * np.linalg.inv(res) @ means\n",
    "get_ef_port_analytically(means, res, target)\n",
    "#optimize(target, means, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45, 0.15])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_propabilities(probabilites, goal_strategies):\n",
    "    goals = np.unique(goal_strategies[goal_strategies > 0])\n",
    "    result = np.zeros(len(goals))\n",
    "    for k in goals:\n",
    "        k_index = np.where(goal_strategies == k)\n",
    "        result[k-1]  = np.take(probabilites, k_index).sum()       \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "probabilites = np.array([0.1,0.3,0.3, 0.15, 0.1, 0.05])\n",
    "goal_strategies = np.array([0,0,1,1,2,2])\n",
    "\n",
    "get_k_propabilities(probabilites, goal_strategies)\n",
    "\n",
    "#result = [0, 0.45, 0.15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-optimisation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bef00bc7c9a78db1045a379974b3641e8d6d719796f9d93b631987f459ca5f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
