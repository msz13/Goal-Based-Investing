{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, NonlinearConstraint\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSCI ACWI', 'MWITR', 'TBSP', 'EURPLN', 'EDO', 'Bloomberg Barclays Global Aggre', 'Gold spot price', 'Global aggregate euro hdg', 'EURO STOXX 50 Daily Leverage', 'Bloomberg Barclays Global Corpo']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 456 entries, 1985-01-01 to 2022-12-01\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Mwig40tr             155 non-null    float64\n",
      " 1   TBSP                 191 non-null    float64\n",
      " 2   EDO                  225 non-null    float64\n",
      " 3   ACWI                 254 non-null    float64\n",
      " 4   GovBondG7            254 non-null    float64\n",
      " 5   GlobalCorporate      123 non-null    float64\n",
      " 6   Gold                 254 non-null    float64\n",
      " 7   GABHDG               61 non-null     float64\n",
      " 8   EURO_STOXX_Leverage  252 non-null    float64\n",
      " 9   Fallen_Angels        78 non-null     float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 55.4 KB\n"
     ]
    }
   ],
   "source": [
    "xl = pd.ExcelFile('wartosci_walorow_12_22.xlsx')\n",
    "sheets = xl.sheet_names\n",
    "\n",
    "merged = xl.parse(sheets.pop(0))\n",
    "print(sheets)\n",
    "\n",
    "for sheet in sheets:\n",
    "    data = xl.parse(sheet)    \n",
    "    merged = merged.merge(data, on='Date', how='left') \n",
    "\n",
    "xl.close()\n",
    "\n",
    "assets = merged.columns[1:]\n",
    "price_changes = merged[assets].pct_change()\n",
    "price_changes.set_index(merged['Date'], inplace=True)\n",
    "\n",
    "euro_assets = ['ACWI', 'GovBondG7', 'GlobalCorporate', 'Gold', 'GABHDG', 'EURO_STOXX_Leverage', 'Fallen_Angels']\n",
    "pln_assets = ['Mwig40tr', 'TBSP', 'EDO']\n",
    "\n",
    "pln = merged[euro_assets].apply(lambda x: x * merged['EURPLN'])\n",
    "pln_chng = pln.pct_change()\n",
    "pln_chng.set_index(merged['Date'], inplace=True)\n",
    "pln_chng = pd.merge(price_changes[pln_assets], pln_chng, left_index=True, right_index=True)\n",
    "\n",
    "assets = pln_chng\n",
    "assets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrinkedCovariance(returns: pd.DataFrame, w: int):\n",
    "    std = np.diag(returns.std()*np.sqrt(12))\n",
    "    corr = returns.corr('pearson')\n",
    "    shrinked_corr = (1-w)*corr + np.ones_like(corr)*w \n",
    "    result = std @ shrinked_corr @ std\n",
    "    return std,corr, shrinked_corr, result\n",
    "\n",
    "def pstd(cov_matrix, weights):\n",
    "    return np.sqrt(weights.T @ cov_matrix @ weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TBSP      ACWI\n",
      "TBSP  0.002233 -0.000662\n",
      "ACWI -0.000662  0.023129\n",
      "[[0.04725282 0.        ]\n",
      " [0.         0.15208061]]\n",
      "          TBSP      ACWI\n",
      "TBSP  1.000000 -0.092152\n",
      "ACWI -0.092152  1.000000\n",
      "          TBSP      ACWI\n",
      "TBSP  1.000000  0.453924\n",
      "ACWI  0.453924  1.000000\n",
      "          0         1\n",
      "0  0.002233  0.003262\n",
      "1  0.003262  0.023129\n",
      "---\n",
      "0.09146392619858458\n",
      "---\n",
      "0.10123873094081719\n"
     ]
    }
   ],
   "source": [
    "assets_names = ['TBSP', 'ACWI']\n",
    "\n",
    "portfolio_returns = assets.iloc[-120:][assets_names]\n",
    "\n",
    "std, corr, sh_corr, res = shrinkedCovariance(portfolio_returns,0.5)\n",
    "cov = portfolio_returns.cov()*12\n",
    "\n",
    "print (portfolio_returns.cov()*12)\n",
    "print(std)\n",
    "print(corr)\n",
    "print(sh_corr)\n",
    "print(res)\n",
    "print('---')\n",
    "print(pstd(cov, np.array([0.4, 0.6])))\n",
    "print('---')\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBSP    0.058287\n",
      "ACWI    0.180158\n",
      "dtype: float64\n",
      "TBSP    0.019728\n",
      "ACWI    0.156034\n",
      "dtype: float64\n",
      "TBSP    0.024732\n",
      "ACWI    0.129339\n",
      "dtype: float64\n",
      "TBSP    0.044049\n",
      "ACWI    0.150289\n",
      "dtype: float64\n",
      "---\n",
      "0.10942527346768507\n",
      "0.09450573239453121\n",
      "0.07687067421906144\n",
      "0.08952406152781506\n",
      "---\n",
      "0.126273078746576\n",
      "0.09980622208789802\n",
      "0.08496410489639229\n",
      "0.10352840991202439\n"
     ]
    }
   ],
   "source": [
    "ret = assets.iloc[-60:][assets_names]\n",
    "ret_24 = assets.iloc[-84:-24][assets_names]\n",
    "ret_48 = assets.iloc[-108:-48][assets_names]\n",
    "ret_150 = assets.iloc[-150:][assets_names]\n",
    "print(ret.std()*np.sqrt(12))\n",
    "print(ret_24.std()*np.sqrt(12))\n",
    "print(ret_48.std()*np.sqrt(12))\n",
    "print(ret_150.std()*np.sqrt(12))\n",
    "print('---')\n",
    "\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0)\n",
    "std, corr, sh_corr, res_24 = shrinkedCovariance(ret_24,0)\n",
    "std, corr, sh_corr, res_48 = shrinkedCovariance(ret_48,0)\n",
    "std, corr, sh_corr, res_150 = shrinkedCovariance(ret_150,0)\n",
    "\n",
    "\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "print(pstd(res_24, np.array([0.4, 0.6])))\n",
    "print(pstd(res_48, np.array([0.4, 0.6])))\n",
    "print(pstd(res_150, np.array([0.4, 0.6])))\n",
    "\n",
    "\n",
    "print('---')\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0.75)\n",
    "std, corr, sh_corr, res_24 = shrinkedCovariance(ret_24,0.75)\n",
    "std, corr, sh_corr, res_48 = shrinkedCovariance(ret_48,0.75)\n",
    "std, corr, sh_corr, res_150 = shrinkedCovariance(ret_150,0.75)\n",
    "\n",
    "print(pstd(res, np.array([0.4, 0.6])))\n",
    "print(pstd(res_24, np.array([0.4, 0.6])))\n",
    "print(pstd(res_48, np.array([0.4, 0.6])))\n",
    "print(pstd(res_150, np.array([0.4, 0.6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ef_port_analytically(rets, covm, targ):\n",
    "    \"\"\"Solve for the efficient frontier weights for a given expected return\n",
    "    vector `rets`, covariance matrix `covm`, and expected portfolio return\n",
    "    `targ`.\n",
    "    \"\"\"\n",
    "    N = rets.shape[0]\n",
    "    u = np.array([targ, 1])[:, None]\n",
    "    U = np.vstack([rets, np.ones_like(rets)]).T\n",
    "\n",
    "    covm_inv = np.linalg.solve(covm, np.eye(N))\n",
    "    M        = U.T @ covm_inv @ U\n",
    "    M_inv    = np.linalg.solve(M, np.eye(2))\n",
    "    weights  = covm_inv @ U @ M_inv @ u\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(expectedMean, means: np.array, cov_table: np.array):\n",
    "\n",
    "    constraint1 = NonlinearConstraint(lambda x : x.sum(),1,1)\n",
    "    constraint2 = NonlinearConstraint(lambda x: x.dot(means)*12, expectedMean, expectedMean)\n",
    "    constraint3 = NonlinearConstraint(lambda x: np.all(np.any([x >=0.05, x == 0], axis=0)).astype(int),True,True)\n",
    "    assets_constraints = [(0.0,1),(0.0,1)]\n",
    "    obj = lambda x: x.T@cov_table@x\n",
    "    start = [1/len(means) for n in range(len(means))]\n",
    "    result = minimize(obj,start,constraints=[constraint1, constraint2],bounds=assets_constraints)\n",
    "    #result = np.append(result.x, [expectedMean], [result.fun])    \n",
    "\n",
    "    return np.array(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9503457 0.0496543]\n",
      "[0.95748907 0.04251093]\n"
     ]
    }
   ],
   "source": [
    "print(optimize(0.07,ret.mean()*12,res.cov()*12))\n",
    "print(optimize(0.06,ret.mean()*12,res.cov()*12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TBSP    0.000041\n",
      "ACWI    0.116699\n",
      "dtype: float64\n",
      "          0         1\n",
      "0  0.003397  0.004986\n",
      "1  0.004986  0.032457\n",
      "0.10703470394342732\n",
      "[[0.31458574]\n",
      " [0.68541426]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.13317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0  0.13317"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = assets.iloc[-60:][assets_names]\n",
    "ret_150 = assets.iloc[-180:][assets_names]\n",
    "\n",
    "means = ret.mean()*12\n",
    "#means = np.array([0.035, 0.085])\n",
    "std, corr, sh_corr, res = shrinkedCovariance(ret,0.5)\n",
    "print(means)\n",
    "print(res)\n",
    "print(pstd(res, np.array([0.5,0.5])))\n",
    "\n",
    "target = 0.08\n",
    "av = 10\n",
    "\n",
    "#1/av * np.linalg.inv(res) @ means\n",
    "w = get_ef_port_analytically(means, res, target)\n",
    "#optimize(target, means, res)\n",
    "print(w)\n",
    "pstd(res, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45, 0.15])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_propabilities(probabilites, goal_strategies):\n",
    "    goals = np.unique(goal_strategies[goal_strategies > 0])\n",
    "    result = np.zeros(len(goals))\n",
    "    for k in goals:\n",
    "        k_index = np.where(goal_strategies == k)\n",
    "        result[k-1]  = np.take(probabilites, k_index).sum()       \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "probabilites = np.array([0.1,0.3,0.3, 0.15, 0.1, 0.05])\n",
    "goal_strategies = np.array([0,0,1,1,2,2])\n",
    "\n",
    "get_k_propabilities(probabilites, goal_strategies)\n",
    "\n",
    "#result = [0, 0.45, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [4]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [[1,2],[3,4]]\n",
    "np.take(arr,[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.368\n"
     ]
    }
   ],
   "source": [
    "def goal_propability(W, G, t, mu, sig):\n",
    "    z = (np.log(W)-np.log(G)-(mu-0.5*np.power(sig,2))*t)/(std*np.sqrt(t))\n",
    "    \n",
    "    return norm.cdf(-z)\n",
    "    \n",
    "def goal_prob2(W, G, t, mu, sig):\n",
    "    z = ((mu-0.5*np.power(sig,2))*np.sqrt(t) - (1/np.sqrt(t))*np.log(G/W))/sig\n",
    "    return norm.cdf(z)\n",
    "\n",
    "W = 90\n",
    "G = 180\n",
    "t = 8\n",
    "mu = 0.08\n",
    "std = 0.09 #0.1375\n",
    "\n",
    "print(np.round(goal_propability(W,G, t, mu, std),3))\n",
    "\n",
    "print(np.round(goal_prob2(W,G, t, mu, std),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39807832, 0.3989146 , 0.39863098, 0.39799177, 0.39738996,\n",
       "        0.39533289],\n",
       "       [0.3975307 , 0.39876124, 0.39885295, 0.39842942, 0.39796736,\n",
       "        0.39624539],\n",
       "       [0.38654689, 0.39126145, 0.39471923, 0.39625193, 0.39706599,\n",
       "        0.39843228],\n",
       "       [0.34858035, 0.35798671, 0.36615426, 0.37050234, 0.37318383,\n",
       "        0.37917046],\n",
       "       [0.30544347, 0.31729017, 0.32806584, 0.33404156, 0.33782924,\n",
       "        0.34663951],\n",
       "       [0.29491427, 0.3071241 , 0.31831316, 0.32455722, 0.32853114,\n",
       "        0.33782924],\n",
       "       [0.38986491, 0.39383772, 0.39657107, 0.39767934, 0.39821519,\n",
       "        0.39890384],\n",
       "       [0.38826772, 0.39261356, 0.39571068, 0.39703183, 0.39770712,\n",
       "        0.39873511],\n",
       "       [0.36827662, 0.3757775 , 0.3820011 , 0.38517375, 0.38707041,\n",
       "        0.39109849],\n",
       "       [0.31911699, 0.33037386, 0.34049871, 0.34605992, 0.34956276,\n",
       "        0.35763595],\n",
       "       [0.27097621, 0.28375838, 0.2956417 , 0.3023529 , 0.30665699,\n",
       "        0.31683856],\n",
       "       [0.25983148, 0.27277316, 0.28487539, 0.29174309, 0.29616098,\n",
       "        0.30665699],\n",
       "       [0.38553242, 0.39045093, 0.39410871, 0.39575893, 0.39665016,\n",
       "        0.39820485],\n",
       "       [0.38362236, 0.38890213, 0.39291503, 0.39477431, 0.39580297,\n",
       "        0.39769367],\n",
       "       [0.36102779, 0.36931731, 0.3763391 , 0.37999169, 0.38220777,\n",
       "        0.38702961],\n",
       "       [0.30892044, 0.32063048, 0.33125348, 0.33713121, 0.34085128,\n",
       "        0.34948574],\n",
       "       [0.25972838, 0.27267124, 0.28477521, 0.29164418, 0.29606302,\n",
       "        0.30656167],\n",
       "       [0.24850292, 0.2615434 , 0.27380597, 0.2807962 , 0.28530581,\n",
       "        0.29606302]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __prob(W0, W1, mean, std, Infusion, Cost, h):\n",
    "    return norm.pdf((np.log(W1/(W0+Infusion+Cost))-(mean-0.5*std**2)*h)/(std*np.sqrt(h)))\n",
    "\n",
    "def calculateTransitionPropabilitiesForAllPorfolios(portfolios,WT,WT1,infusions, h=1):\n",
    "    l = len(portfolios)\n",
    "    i = len(WT)\n",
    "    b = ((portfolios[:,0]-0.5*portfolios[:,1]**2)*h)/(std*np.sqrt(h))\n",
    "    bi = np.repeat(b, i).reshape(l*i,1)\n",
    "    Wt1 = np.tile(WT1, (l*i,1))\n",
    "    Wt = np.tile(WT,(l,1)).reshape(i*l,1)+infusions\n",
    "    result = np.log(Wt1/Wt)- bi\n",
    "    return norm.pdf(result)\n",
    "\n",
    "\n",
    "portfolios = np.array([[0.0526, 0.0374], [0.07059443, 0.103057  ], [0.0886, 0.1954]])\n",
    "WT = np.array([49,50,60,80,100,105])\n",
    "WT1 = [90,95,100,103,105,110]\n",
    "VT1 = [0,0,0,100,100,100]\n",
    "c = 50\n",
    "#goals = [[50, 80], [30, 50],]\n",
    "VTc0 = np.array([29.014, 29.55, 77.286, 95.997])\n",
    "\n",
    "#probabilities = calculateTransitionPropabilitiesForAllPorfolios(portfolios,WT,WT1,3)\n",
    "\n",
    "#print(probabilities)\n",
    "\n",
    "calculateTransitionPropabilitiesForAllPorfolios(portfolios,WT,WT1,5,1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b47aa380712f7fc5fc0f04082b0c6bfb60a158886ac5c7ca524c8519d830ecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
